{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income_bracket    32561 non-null object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    >50K\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = pd.get_dummies(df['income_bracket'],drop_first=True)\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,label],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('income_bracket',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country   >50K  \n",
       "0             0              40   United-States      0  \n",
       "1             0              13   United-States      0  \n",
       "2             0              40   United-States      0  \n",
       "3             0              40   United-States      0  \n",
       "4             0              40            Cuba      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', ' >50K'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(' >50K',axis=1), df[' >50K'], test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      " >50K             32561 non-null uint8\n",
      "dtypes: int64(5), object(8), uint8(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass',hash_bucket_size=50)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education',hash_bucket_size=50)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status',hash_bucket_size=50)\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation',hash_bucket_size=200)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship',hash_bucket_size=50)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket('race',hash_bucket_size=50)\n",
    "gender = tf.feature_column.categorical_column_with_hash_bucket('gender',hash_bucket_size=10)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country',hash_bucket_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [age,workclass,education,education_num,marital_status,occupation,relationship,\n",
    "race,gender,capital_gain,capital_loss,hours_per_week,native_country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100, num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvs6vih1x\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpvs6vih1x', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f27592ff908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols,n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpvs6vih1x/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 143.22\n",
      "INFO:tensorflow:loss = 246.42032, step = 101 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.765\n",
      "INFO:tensorflow:loss = 42.198475, step = 201 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.349\n",
      "INFO:tensorflow:loss = 20.927717, step = 301 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.42\n",
      "INFO:tensorflow:loss = 150.85828, step = 401 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.187\n",
      "INFO:tensorflow:loss = 81.21872, step = 501 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.909\n",
      "INFO:tensorflow:loss = 33.986687, step = 601 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.572\n",
      "INFO:tensorflow:loss = 85.794334, step = 701 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.255\n",
      "INFO:tensorflow:loss = 149.00429, step = 801 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.316\n",
      "INFO:tensorflow:loss = 89.76625, step = 901 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.905\n",
      "INFO:tensorflow:loss = 34.682495, step = 1001 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.581\n",
      "INFO:tensorflow:loss = 346.5057, step = 1101 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.141\n",
      "INFO:tensorflow:loss = 51.646614, step = 1201 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.002\n",
      "INFO:tensorflow:loss = 344.94104, step = 1301 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.991\n",
      "INFO:tensorflow:loss = 101.70793, step = 1401 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.691\n",
      "INFO:tensorflow:loss = 357.85248, step = 1501 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.768\n",
      "INFO:tensorflow:loss = 442.5113, step = 1601 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.359\n",
      "INFO:tensorflow:loss = 232.97227, step = 1701 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.094\n",
      "INFO:tensorflow:loss = 29.9261, step = 1801 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.51\n",
      "INFO:tensorflow:loss = 53.959248, step = 1901 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.485\n",
      "INFO:tensorflow:loss = 94.553406, step = 2001 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.961\n",
      "INFO:tensorflow:loss = 51.81696, step = 2101 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.06\n",
      "INFO:tensorflow:loss = 30.543402, step = 2201 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.752\n",
      "INFO:tensorflow:loss = 39.567585, step = 2301 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.269\n",
      "INFO:tensorflow:loss = 58.915134, step = 2401 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.015\n",
      "INFO:tensorflow:loss = 145.68192, step = 2501 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.274\n",
      "INFO:tensorflow:loss = 41.102585, step = 2601 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.785\n",
      "INFO:tensorflow:loss = 400.7919, step = 2701 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.73\n",
      "INFO:tensorflow:loss = 67.435455, step = 2801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.105\n",
      "INFO:tensorflow:loss = 37.68905, step = 2901 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.54\n",
      "INFO:tensorflow:loss = 80.676865, step = 3001 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.366\n",
      "INFO:tensorflow:loss = 49.007515, step = 3101 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.981\n",
      "INFO:tensorflow:loss = 37.51186, step = 3201 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.85\n",
      "INFO:tensorflow:loss = 20.583296, step = 3301 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.078\n",
      "INFO:tensorflow:loss = 71.39854, step = 3401 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.084\n",
      "INFO:tensorflow:loss = 93.127655, step = 3501 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.97\n",
      "INFO:tensorflow:loss = 44.822433, step = 3601 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.766\n",
      "INFO:tensorflow:loss = 33.34963, step = 3701 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.552\n",
      "INFO:tensorflow:loss = 418.27917, step = 3801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.25\n",
      "INFO:tensorflow:loss = 42.379597, step = 3901 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.864\n",
      "INFO:tensorflow:loss = 92.91012, step = 4001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.773\n",
      "INFO:tensorflow:loss = 49.30735, step = 4101 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.538\n",
      "INFO:tensorflow:loss = 30.094467, step = 4201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.364\n",
      "INFO:tensorflow:loss = 27.463781, step = 4301 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.168\n",
      "INFO:tensorflow:loss = 52.90747, step = 4401 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.07\n",
      "INFO:tensorflow:loss = 82.50812, step = 4501 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.486\n",
      "INFO:tensorflow:loss = 47.16278, step = 4601 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.066\n",
      "INFO:tensorflow:loss = 304.19852, step = 4701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.154\n",
      "INFO:tensorflow:loss = 63.190994, step = 4801 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.296\n",
      "INFO:tensorflow:loss = 39.288525, step = 4901 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.657\n",
      "INFO:tensorflow:loss = 95.80709, step = 5001 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.058\n",
      "INFO:tensorflow:loss = 54.122566, step = 5101 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.482\n",
      "INFO:tensorflow:loss = 39.558014, step = 5201 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.452\n",
      "INFO:tensorflow:loss = 51.14433, step = 5301 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.368\n",
      "INFO:tensorflow:loss = 22.718262, step = 5401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.669\n",
      "INFO:tensorflow:loss = 38.238914, step = 5501 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.75\n",
      "INFO:tensorflow:loss = 43.06594, step = 5601 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.381\n",
      "INFO:tensorflow:loss = 40.154957, step = 5701 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.144\n",
      "INFO:tensorflow:loss = 33.507637, step = 5801 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.686\n",
      "INFO:tensorflow:loss = 16.13195, step = 5901 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.715\n",
      "INFO:tensorflow:loss = 30.138107, step = 6001 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.741\n",
      "INFO:tensorflow:loss = 175.99504, step = 6101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.701\n",
      "INFO:tensorflow:loss = 48.39212, step = 6201 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.206\n",
      "INFO:tensorflow:loss = 46.5679, step = 6301 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.326\n",
      "INFO:tensorflow:loss = 40.443832, step = 6401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.227\n",
      "INFO:tensorflow:loss = 174.28308, step = 6501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.002\n",
      "INFO:tensorflow:loss = 42.77585, step = 6601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.397\n",
      "INFO:tensorflow:loss = 52.925182, step = 6701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.202\n",
      "INFO:tensorflow:loss = 93.3643, step = 6801 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.279\n",
      "INFO:tensorflow:loss = 78.758125, step = 6901 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.211\n",
      "INFO:tensorflow:loss = 36.484104, step = 7001 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.284\n",
      "INFO:tensorflow:loss = 33.27453, step = 7101 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.291\n",
      "INFO:tensorflow:loss = 43.72169, step = 7201 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.431\n",
      "INFO:tensorflow:loss = 272.9815, step = 7301 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.063\n",
      "INFO:tensorflow:loss = 52.095722, step = 7401 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.945\n",
      "INFO:tensorflow:loss = 54.611427, step = 7501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.907\n",
      "INFO:tensorflow:loss = 32.546856, step = 7601 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.555\n",
      "INFO:tensorflow:loss = 90.01787, step = 7701 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.207\n",
      "INFO:tensorflow:loss = 44.044586, step = 7801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.114\n",
      "INFO:tensorflow:loss = 26.080725, step = 7901 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.044\n",
      "INFO:tensorflow:loss = 29.95362, step = 8001 (0.415 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 263.773\n",
      "INFO:tensorflow:loss = 52.06845, step = 8101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.012\n",
      "INFO:tensorflow:loss = 61.38585, step = 8201 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.652\n",
      "INFO:tensorflow:loss = 51.432526, step = 8301 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.681\n",
      "INFO:tensorflow:loss = 52.52353, step = 8401 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.42\n",
      "INFO:tensorflow:loss = 100.10341, step = 8501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.175\n",
      "INFO:tensorflow:loss = 109.18536, step = 8601 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.733\n",
      "INFO:tensorflow:loss = 39.684464, step = 8701 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.762\n",
      "INFO:tensorflow:loss = 32.026104, step = 8801 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.684\n",
      "INFO:tensorflow:loss = 46.209015, step = 8901 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.121\n",
      "INFO:tensorflow:loss = 30.500957, step = 9001 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.733\n",
      "INFO:tensorflow:loss = 29.315536, step = 9101 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.4\n",
      "INFO:tensorflow:loss = 19.141594, step = 9201 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.867\n",
      "INFO:tensorflow:loss = 27.164814, step = 9301 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.427\n",
      "INFO:tensorflow:loss = 70.383606, step = 9401 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.673\n",
      "INFO:tensorflow:loss = 28.796732, step = 9501 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.113\n",
      "INFO:tensorflow:loss = 93.25829, step = 9601 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.388\n",
      "INFO:tensorflow:loss = 26.658615, step = 9701 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.804\n",
      "INFO:tensorflow:loss = 51.774155, step = 9801 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.028\n",
      "INFO:tensorflow:loss = 39.87158, step = 9901 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.62\n",
      "INFO:tensorflow:loss = 35.32574, step = 10001 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.919\n",
      "INFO:tensorflow:loss = 33.35677, step = 10101 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.219\n",
      "INFO:tensorflow:loss = 43.520424, step = 10201 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.109\n",
      "INFO:tensorflow:loss = 32.081646, step = 10301 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.07\n",
      "INFO:tensorflow:loss = 86.20189, step = 10401 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.062\n",
      "INFO:tensorflow:loss = 37.049286, step = 10501 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.472\n",
      "INFO:tensorflow:loss = 44.529213, step = 10601 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.548\n",
      "INFO:tensorflow:loss = 45.94912, step = 10701 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.671\n",
      "INFO:tensorflow:loss = 45.809986, step = 10801 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.672\n",
      "INFO:tensorflow:loss = 38.539543, step = 10901 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.28\n",
      "INFO:tensorflow:loss = 76.602196, step = 11001 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.704\n",
      "INFO:tensorflow:loss = 32.21924, step = 11101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.143\n",
      "INFO:tensorflow:loss = 41.096813, step = 11201 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.653\n",
      "INFO:tensorflow:loss = 31.837341, step = 11301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.191\n",
      "INFO:tensorflow:loss = 73.59246, step = 11401 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.872\n",
      "INFO:tensorflow:loss = 25.160336, step = 11501 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.238\n",
      "INFO:tensorflow:loss = 31.721083, step = 11601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.965\n",
      "INFO:tensorflow:loss = 25.334461, step = 11701 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.345\n",
      "INFO:tensorflow:loss = 39.560112, step = 11801 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.459\n",
      "INFO:tensorflow:loss = 37.91069, step = 11901 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.304\n",
      "INFO:tensorflow:loss = 34.6183, step = 12001 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.95\n",
      "INFO:tensorflow:loss = 128.01309, step = 12101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.028\n",
      "INFO:tensorflow:loss = 37.388824, step = 12201 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.278\n",
      "INFO:tensorflow:loss = 38.50973, step = 12301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.509\n",
      "INFO:tensorflow:loss = 73.741875, step = 12401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.318\n",
      "INFO:tensorflow:loss = 24.376266, step = 12501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.921\n",
      "INFO:tensorflow:loss = 36.720753, step = 12601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.344\n",
      "INFO:tensorflow:loss = 51.184765, step = 12701 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.055\n",
      "INFO:tensorflow:loss = 33.542503, step = 12801 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.569\n",
      "INFO:tensorflow:loss = 33.638996, step = 12901 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.985\n",
      "INFO:tensorflow:loss = 46.38207, step = 13001 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.229\n",
      "INFO:tensorflow:loss = 34.85008, step = 13101 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.983\n",
      "INFO:tensorflow:loss = 35.919804, step = 13201 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.271\n",
      "INFO:tensorflow:loss = 33.17784, step = 13301 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.903\n",
      "INFO:tensorflow:loss = 45.001045, step = 13401 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.145\n",
      "INFO:tensorflow:loss = 50.597843, step = 13501 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.315\n",
      "INFO:tensorflow:loss = 31.73036, step = 13601 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.689\n",
      "INFO:tensorflow:loss = 38.886078, step = 13701 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.692\n",
      "INFO:tensorflow:loss = 44.040768, step = 13801 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.394\n",
      "INFO:tensorflow:loss = 36.15823, step = 13901 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.18\n",
      "INFO:tensorflow:loss = 46.830093, step = 14001 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.445\n",
      "INFO:tensorflow:loss = 29.298512, step = 14101 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.216\n",
      "INFO:tensorflow:loss = 47.060387, step = 14201 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.362\n",
      "INFO:tensorflow:loss = 234.11652, step = 14301 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.668\n",
      "INFO:tensorflow:loss = 40.6879, step = 14401 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.551\n",
      "INFO:tensorflow:loss = 42.027576, step = 14501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.346\n",
      "INFO:tensorflow:loss = 55.4188, step = 14601 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.475\n",
      "INFO:tensorflow:loss = 29.69635, step = 14701 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.342\n",
      "INFO:tensorflow:loss = 37.705757, step = 14801 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.294\n",
      "INFO:tensorflow:loss = 33.18162, step = 14901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.444\n",
      "INFO:tensorflow:loss = 37.948044, step = 15001 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.728\n",
      "INFO:tensorflow:loss = 34.894444, step = 15101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.25\n",
      "INFO:tensorflow:loss = 29.914585, step = 15201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.745\n",
      "INFO:tensorflow:loss = 133.42783, step = 15301 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.413\n",
      "INFO:tensorflow:loss = 493.56482, step = 15401 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.503\n",
      "INFO:tensorflow:loss = 39.35732, step = 15501 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.38\n",
      "INFO:tensorflow:loss = 31.59343, step = 15601 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.099\n",
      "INFO:tensorflow:loss = 39.270607, step = 15701 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.583\n",
      "INFO:tensorflow:loss = 45.463383, step = 15801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.94\n",
      "INFO:tensorflow:loss = 75.80542, step = 15901 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.566\n",
      "INFO:tensorflow:loss = 36.044235, step = 16001 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.059\n",
      "INFO:tensorflow:loss = 31.11878, step = 16101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.285\n",
      "INFO:tensorflow:loss = 23.486221, step = 16201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.667\n",
      "INFO:tensorflow:loss = 31.421804, step = 16301 (0.374 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 264.128\n",
      "INFO:tensorflow:loss = 27.077293, step = 16401 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.944\n",
      "INFO:tensorflow:loss = 38.016277, step = 16501 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.731\n",
      "INFO:tensorflow:loss = 37.82157, step = 16601 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.933\n",
      "INFO:tensorflow:loss = 75.68471, step = 16701 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.128\n",
      "INFO:tensorflow:loss = 21.924053, step = 16801 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.015\n",
      "INFO:tensorflow:loss = 45.71966, step = 16901 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.751\n",
      "INFO:tensorflow:loss = 46.183266, step = 17001 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.921\n",
      "INFO:tensorflow:loss = 306.75726, step = 17101 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.293\n",
      "INFO:tensorflow:loss = 30.931574, step = 17201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.285\n",
      "INFO:tensorflow:loss = 49.417862, step = 17301 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.567\n",
      "INFO:tensorflow:loss = 136.98578, step = 17401 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.782\n",
      "INFO:tensorflow:loss = 39.55017, step = 17501 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.892\n",
      "INFO:tensorflow:loss = 24.563356, step = 17601 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.09\n",
      "INFO:tensorflow:loss = 37.86415, step = 17701 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.262\n",
      "INFO:tensorflow:loss = 43.86175, step = 17801 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.127\n",
      "INFO:tensorflow:loss = 39.79483, step = 17901 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.833\n",
      "INFO:tensorflow:loss = 35.130642, step = 18001 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.929\n",
      "INFO:tensorflow:loss = 27.800985, step = 18101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.935\n",
      "INFO:tensorflow:loss = 45.350586, step = 18201 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.849\n",
      "INFO:tensorflow:loss = 68.867, step = 18301 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.684\n",
      "INFO:tensorflow:loss = 42.37272, step = 18401 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.671\n",
      "INFO:tensorflow:loss = 28.434387, step = 18501 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.574\n",
      "INFO:tensorflow:loss = 185.80508, step = 18601 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.872\n",
      "INFO:tensorflow:loss = 27.883356, step = 18701 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.131\n",
      "INFO:tensorflow:loss = 41.29751, step = 18801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.624\n",
      "INFO:tensorflow:loss = 26.854723, step = 18901 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.403\n",
      "INFO:tensorflow:loss = 33.19217, step = 19001 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.785\n",
      "INFO:tensorflow:loss = 31.356361, step = 19101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.805\n",
      "INFO:tensorflow:loss = 242.36354, step = 19201 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.848\n",
      "INFO:tensorflow:loss = 34.04174, step = 19301 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.015\n",
      "INFO:tensorflow:loss = 30.732292, step = 19401 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.616\n",
      "INFO:tensorflow:loss = 32.75391, step = 19501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.791\n",
      "INFO:tensorflow:loss = 58.74432, step = 19601 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.961\n",
      "INFO:tensorflow:loss = 27.476606, step = 19701 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.399\n",
      "INFO:tensorflow:loss = 31.825586, step = 19801 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.397\n",
      "INFO:tensorflow:loss = 41.45446, step = 19901 (0.380 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpvs6vih1x/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 39.148506.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f27316ce518>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=100, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvs6vih1x/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for pred in model.predict(pred_input_func):\n",
    "\tpredictions.append(pred['class_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7436\n",
      "          1       0.69      0.61      0.65      2333\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "\n",
      "\n",
      "[[6805  631]\n",
      " [ 915 1418]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
